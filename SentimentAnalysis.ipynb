{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1c0813",
   "metadata": {},
   "source": [
    "### In this project, i implemented a ML model using LSTM  and the objective is to predict the sentiment as positive or negative on twitter_training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732da6bb",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e819b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\adero\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # to read and manage the dataset\n",
    "import tensorflow as tf # for deep learning models\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # used to pad a sequence with zeros if the sequence length is less than the required length\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # used for text partitioning\n",
    "from tensorflow.keras.models import Sequential # used the sequence model for sequence data analysis\n",
    "from tensorflow.keras.layers import LSTM,Dense, Dropout, SpatialDropout1D # layers to be used to build the DL model\n",
    "from tensorflow.keras.layers import Embedding \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb67a9",
   "metadata": {},
   "source": [
    "Read the dataset with the following variables names 'seq','brand','sentiment','text' and print the first 5 rows. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a52aa1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seq        brand sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('twitter_training.csv', names = ['seq','brand','sentiment','text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e4f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only the 'sentiment'and 'text' columns to analyze\n",
    "data = df[['sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4908cbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74673</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74674</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74675</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74678 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "0      Positive  im getting on borderlands and i will murder yo...\n",
       "1      Positive  I am coming to the borders and I will kill you...\n",
       "2      Positive  im getting on borderlands and i will kill you ...\n",
       "3      Positive  im coming on borderlands and i will murder you...\n",
       "4      Positive  im getting on borderlands 2 and i will murder ...\n",
       "...         ...                                                ...\n",
       "74673  Positive  Just realized that the Windows partition of my...\n",
       "74674  Positive  Just realized that my Mac window partition is ...\n",
       "74675  Positive  Just realized the windows partition of my Mac ...\n",
       "74676  Positive  Just realized between the windows partition of...\n",
       "74677  Positive  Just like the windows partition of my Mac is l...\n",
       "\n",
       "[74678 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b77997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative      22538\n",
      "Positive      20832\n",
      "Neutral       18318\n",
      "Irrelevant    12990\n",
      "Name: sentiment, dtype: int64\n",
      "Negative    22538\n",
      "Positive    20832\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print the unique labels (sentiments) and their frequencies\n",
    "print(data[\"sentiment\"].value_counts())\n",
    "\n",
    "#filter out the Neutral labels\n",
    "data = data[data['sentiment'] != 'Neutral']\n",
    "\n",
    "#filter out the Irrelevant labels\n",
    "data = data[data['sentiment'] != 'Irrelevant']\n",
    "\n",
    "#print the selected labels and the frequencies\n",
    "print(data[\"sentiment\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eecf14f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 0, ..., 0, 0, 0], dtype=int64), Index(['Positive', 'Negative'], dtype='object'))\n"
     ]
    }
   ],
   "source": [
    "# converts sentiment labels to numeric values,using factorize() function.\n",
    "sentiment_label = data.sentiment.factorize()\n",
    "print(sentiment_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ae6dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the NAN values (null) by either drop the rows with NAN or replace by ' '\n",
    "nan_idx = data[pd.isnull(data['text'])].index.tolist() # return all rows (index) with null data\n",
    "data.loc[nan_idx, 'text'] = ' ' #replace the null value wilth \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "565a2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values of the 'text' column as the input sequence\n",
    "InputData = data.text.values # this is the input sequence. To process the sequence data (the text), we need to do the following:\n",
    "# 1- tokenize the data using the Tokenizer() function, set the word limit to 5000\n",
    "# 2- convert the text sequence into sequence of codes (numbers) using the texts_to_sequences function\n",
    "# 3- pad the sequence with zeros if the length is less than 200 using the pad_sequence function\n",
    "\n",
    "# num_words: the maximum number of words to keep, \n",
    "# based on word frequency. Only the most common num_words-1 words will be kept.\n",
    "tokenizer = Tokenizer(num_words=5000) \n",
    "tokenizer.fit_on_texts(InputData)\n",
    "encoded_docs = tokenizer.texts_to_sequences(InputData) # convert to codes\n",
    "\n",
    "# maxlen: Optional Int, maximum length of all sequences. \n",
    "# If not provided, sequences will be padded to the length of the longest individual sequence.\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=200)\n",
    "#print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e58918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im getting on borderlands and i will murder you all ,\n",
      "[271, 146, 14, 113, 4, 2, 60, 1508, 13, 27]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0  271  146   14  113    4    2\n",
      "   60 1508   13   27]\n"
     ]
    }
   ],
   "source": [
    "# to show the text and its code and then the padding to have fixed sequence size\n",
    "print(InputData[0])\n",
    "print(encoded_docs[0])\n",
    "print(padded_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ad2be08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\adero\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\adero\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 32)           662592    \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 200, 32)           0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50)                16600     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 679243 (2.59 MB)\n",
      "Trainable params: 679243 (2.59 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create a deep learning sequential model by adding the following layers (you can modify)\n",
    "#The Dropout layer randomly sets input units to 0 \n",
    "# with a frequency of rate at each step during training time, which helps prevent overfitting.\n",
    "\n",
    "#Embedding layer enables us to convert each word into a fixed length vector of defined size.\n",
    "embedding_vector_length = 32\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length,     \n",
    "                                     input_length=200) )\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', \n",
    "                           metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9a0e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\adero\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\adero\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1085/1085 [==============================] - 173s 155ms/step - loss: 0.4478 - accuracy: 0.7811 - val_loss: 0.5397 - val_accuracy: 0.7527\n"
     ]
    }
   ],
   "source": [
    "# train the model with the fit function on the dataset\n",
    "Trained_Model = model.fit(padded_sequence,sentiment_label[0],\n",
    "                  validation_split=0.2, epochs=1, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd16db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 979, 7, 8, 1262, 6, 132, 131]]\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to test any sequence for example \"the quality of this product is very bad\"\n",
    "# The same sequence analysis process needs to be done before applying the model\n",
    "\n",
    "test_sentence =\"the quality of this product is very bad\"\n",
    "tokenizer.fit_on_texts(test_sentence)\n",
    "tw = tokenizer.texts_to_sequences([test_sentence])\n",
    "print(tw)\n",
    "tw = pad_sequences(tw,maxlen=200)\n",
    "\n",
    "prediction = int(model.predict(tw).round().item())\n",
    "print (sentiment_label[1][prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7be8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
